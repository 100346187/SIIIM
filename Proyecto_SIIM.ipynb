{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto SIIM.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "848d4aceef64437ebfcea3df53b7547d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d84ccc23a49e4458be366089e12e4c64",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_54293a2df7c74dfe95e55b0064470277",
              "IPY_MODEL_20279f387846425faa55c9ab157b871d"
            ]
          }
        },
        "d84ccc23a49e4458be366089e12e4c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54293a2df7c74dfe95e55b0064470277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c91d255980d945c19dbbd9bccc6f1ccb",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 31519111,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 31519111,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d9a1cc7c41d4c4a806bbbc410ed3747"
          }
        },
        "20279f387846425faa55c9ab157b871d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41b2187312a04e66bda791453715fd01",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30.1M/30.1M [00:00&lt;00:00, 102MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2fff500aff3435db56bedf4fc7424b7"
          }
        },
        "c91d255980d945c19dbbd9bccc6f1ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d9a1cc7c41d4c4a806bbbc410ed3747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41b2187312a04e66bda791453715fd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2fff500aff3435db56bedf4fc7424b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKh2OzCybomS"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import *\n",
        "from torch import nn\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "import random\n",
        "\n",
        "path = Path(\"/content/drive/My Drive/SIIM-ISIC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOegu9J8ORsw"
      },
      "source": [
        "## Carga y procesamiento de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J10a7GOiMx4"
      },
      "source": [
        "### Procesamiento\n",
        "En esta sección se cargan los datos a partir del archivo train_concat.csv, obtenido desde ...\n",
        "\n",
        "Este conjunto de datos incluye más imágenes de melanomas que el original de la competición y sus imágenes tienen como resolución máxima 256x256. En total son alrededor de 37000, de los cuales 5000 son imágenes de melanomas (frente a las 500 muestras originales).\n",
        "\n",
        "Debido a las limitaciones de Google Drive se ha reducido el tamaño del dataset ejecutando la siguiente línea de código, dejando el dataset en 12000 imágenes, siendo 5000 positivos (melanomas) y 7000 negativos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei8OBYaTh9sh",
        "outputId": "f5cc67d2-a042-483d-d948-481bf1d2a02f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Esta sección está comentada para evitar ejecuciones no voluntarias\n",
        "\"\"\"\n",
        "\n",
        "d = pd.read_csv(path/\"train_concat.csv\")\n",
        "positive = d[d.target==1]\n",
        "neg_idx = list(set(list(range(len(d)))) - set(positive.index))\n",
        "negative = d.iloc[neg_idx]\n",
        "new_data = positive.append(negative.sample(n=7000), ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
        "new_data.to_csv(path/\"short_data.csv\", index=False)\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nd = pd.read_csv(path/\"train_concat.csv\")\\npositive = d[d.target==1]\\nneg_idx = list(set(list(range(len(d)))) - set(positive.index))\\nnegative = d.iloc[neg_idx]\\nnew_data = positive.append(negative.sample(n=7000), ignore_index=True).sample(frac=1).reset_index(drop=True)\\nnew_data.to_csv(path/\"short_data.csv\", index=False)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpddax_uhjhw"
      },
      "source": [
        "### Carga"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxGRiuFxP298"
      },
      "source": [
        "def split_from_csv(path_csv, pct_split):\n",
        "    total_data = pd.read_csv(path_csv)\n",
        "    valid_data = total_data.sample(frac=pct_split)\n",
        "    idxs = list(set(list(range(len(total_data)))) - set(valid_data.index))\n",
        "    train_data = total_data.iloc[idxs]\n",
        "\n",
        "    return train_data.reset_index(drop=True), valid_data.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjEIf1MrQ_mk",
        "outputId": "96bb7524-ead9-4372-8f8b-df8099c548dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t, v = split_from_csv(path/\"short_data.csv\", 0.2)\n",
        "len(t), len(v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9685, 2421)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_CTAnE9cr2V"
      },
      "source": [
        "#### Dataset sin metadatos\n",
        "Debe usarse para el modelo de la ResNet modificada y para el primer modelo con EfficientNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIuqZdsgQ_17"
      },
      "source": [
        "class Dataset_from_csv(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset creado teniendo las imágenes en una carpeta y las etiquetas en un \n",
        "    csv en el que se mencionan los nombres de las imágenes de entrada a las que \n",
        "    corresponde cada etiqueta.\n",
        "    \"\"\"\n",
        "    def __init__(self, path, dataframe, dir_images, transforms=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            path (Path Object): Ruta del directorio principal\n",
        "            csv_file (string): Nombre del csv.\n",
        "            dir_images (string): Ruta a la carpeta con las imágenes.\n",
        "            transforms (callable, optional): Lista de posibles transformaciones\n",
        "                hecha con Compose. Debe acabar con ToTensor.\n",
        "        \"\"\"\n",
        "        self.path = path\n",
        "        self.labels = dataframe\n",
        "        self.path_images = dir_images\n",
        "        self.transforms = transforms\n",
        "\n",
        "        #Cargamos las imágenes para facilitar la velocidad del entrenamiento\n",
        "        self.loaded_images = {}\n",
        "        count = 0\n",
        "        print(\"Inicio de la carga de archivos.\")\n",
        "        for name in dataframe.image_name:\n",
        "            if (count%20)==0: print(f\"Progreso: {round(count*100/len(dataframe), 2)}%\")\n",
        "            img_name = path/dir_images/f\"{name}.jpg\"\n",
        "            image = cv2.imread(os.path.join(img_name))\n",
        "            self.loaded_images[name] = image\n",
        "            count += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.labels.iloc[idx, 0]\n",
        "        image = self.loaded_images[img_name]\n",
        "        im_label = np.array(self.labels.iloc[idx].target.squeeze(-1)).astype(\"float\") # reshape(-1,2) si son varias etiquetas\n",
        "        sample = {\"image\": image, \"label\": im_label}\n",
        "\n",
        "        if self.transforms:\n",
        "            sample[\"image\"] = self.transforms(sample[\"image\"])\n",
        "\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9QF_gJHc4GO"
      },
      "source": [
        "#### Dataset con metadatos\n",
        "Debe usarse para el modelo de EfficientNet con metadatos.\n",
        "\n",
        "Los datos incluyen más información que la imagen y el diagnóstico. Alguno de estos datos accesorios son el sexo, la edad y el lugar anatómico en el que se ha detectado la mancha."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gdBeBGUdTmP"
      },
      "source": [
        "class ImageDataset_label_from_dataframe(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset creado teniendo las imágenes en una carpeta y las etiquetas en un \n",
        "    csv en el que se mencionan los nombres de las imágenes de entrada a las que \n",
        "    corresponde cada etiqueta.\n",
        "    \"\"\"\n",
        "    def __init__(self, path, dataframe, dir_images, transforms=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            path (Path Object): Ruta del directorio principal\n",
        "            csv_file (string): Nombre del csv.\n",
        "            dir_images (string): Ruta a la carpeta con las imágenes.\n",
        "            transforms (callable, optional): Lista de posibles transformaciones\n",
        "                hecha con Compose. Debe acabar con ToTensor.\n",
        "        \"\"\"\n",
        "        self.path = path\n",
        "        self.data = dataframe\n",
        "        self.meta = pd.concat([pd.get_dummies(dataframe[[\"sex\", \"anatom_site_general_challenge\"]]), dataframe[\"age_approx\"].fillna(dataframe.age_approx.mean())], axis=1)\n",
        "        self.path_images = dir_images\n",
        "        self.transforms = transforms\n",
        "\n",
        "        #Cargamos las imágenes para facilitar la velocidad del entrenamiento\n",
        "        self.loaded_images = {}\n",
        "        count = 0\n",
        "        print(\"Inicio de la carga de archivos.\")\n",
        "        for name in self.data.image_name:\n",
        "            if (count%20)==0: print(f\"Progreso: {round(count*100/len(dataframe), 2)}%\")\n",
        "            img_name = path/dir_images/f\"{name}.jpg\"\n",
        "            image = cv2.imread(os.path.join(img_name))\n",
        "            self.loaded_images[name] = image\n",
        "            count += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.data.iloc[idx, 0]\n",
        "        image = self.loaded_images[img_name]\n",
        "        im_label = np.array(self.data.iloc[idx].target.squeeze(-1)).astype(\"float\") # reshape(-1,2) si son varias etiquetas\n",
        "        sample = {\"image\": image, \"label\": im_label}\n",
        "        sample_meta = np.array(self.meta.iloc[idx].values, dtype=np.float32)\n",
        "\n",
        "        if self.transforms:\n",
        "            sample[\"image\"] = self.transforms(sample[\"image\"])\n",
        "\n",
        "        return sample, sample_meta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVVFlfVdIye"
      },
      "source": [
        "#### Data augmentation y carga de los datos en RAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZBGEdSAIuA-"
      },
      "source": [
        "Las imágenes de manchas en la piel permiten un *data augmentation* bastante agresivo, combinando volteos de la imagen (tanto en el eje vertical como en el horizontal) y rotaciones. \n",
        "\n",
        "Debido a que el *dataset* ampliado incluye imágenes de melanomas vistas a través de un microscopio incluímos una transformación que simula este efecto para que estar rodeado de una zona negra no permita a la red concluir que la imagen es un melanoma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KSYjduFRAEr"
      },
      "source": [
        "# Tomado de https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/159476\n",
        "import cv2\n",
        "class Microscope:\n",
        "    def __init__(self, p: float = 0.5):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if random.random() < self.p:\n",
        "            circle = cv2.circle((np.ones(img.shape) * 255).astype(np.uint8),\n",
        "                        (img.shape[0]//2, img.shape[1]//2),\n",
        "                        random.randint(img.shape[0]//2 - 3, img.shape[0]//2 + 15),\n",
        "                        (0, 0, 0),\n",
        "                        -1)\n",
        "\n",
        "            mask = circle - 255\n",
        "            img = np.multiply(img, mask)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}(p={self.p})'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwpNxYEIQ_78",
        "outputId": "c0648b1e-8946-4d69-da93-10996e832a35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "size = 128\n",
        "!pip install torchtoolbox\n",
        "# No se usan las transformaciones de Pytorch porque hemos abierto las imágenes con cv2\n",
        "import torchtoolbox.transform as trans\n",
        "\n",
        "tsfm = trans.Compose([\n",
        "        trans.Resize(size),\n",
        "        Microscope(),\n",
        "        trans.RandomHorizontalFlip(),\n",
        "        trans.RandomVerticalFlip(),\n",
        "        trans.RandomRotation(30),\n",
        "        trans.ToTensor(),\n",
        "        #[0.5568, 0.5837, 0.7436] mean\n",
        "        #[0.1409, 0.1247, 0.1067] std\n",
        "        trans.Normalize((0.5568, 0.5837, 0.7436), (0.1409, 0.1247, 0.1067))\n",
        "    ])\n",
        "\n",
        "tsfm2 = trans.Compose([\n",
        "        trans.Resize(size),\n",
        "        trans.ToTensor(),\n",
        "        trans.Normalize((0.5568, 0.5837, 0.7436), (0.1409, 0.1247, 0.1067))\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtoolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/b3/720399783618f307c6b1cac4d2507602514720df66f26ccb57319a75d9e1/torchtoolbox-0.1.5-py3-none-any.whl (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 23.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 25.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 40kB 10.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 51kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: lmdb in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (0.99)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (1.18.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (4.41.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torchtoolbox) (0.17.0)\n",
            "Installing collected packages: torchtoolbox\n",
            "Successfully installed torchtoolbox-0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkZaUgs2KHew"
      },
      "source": [
        "Cargamos los datos en RAM porque Google Drive toma mucho tiempo para abrir las imágenes. Es por esto que abrimos todas las imágenes al principio para tenerlos ya en memoria, concretamente en una lista, para agilizar el acceso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3h2MoznQ_t0",
        "outputId": "f8f0dd41-78b0-4d71-9fc5-e3e78568bc8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "folder = \"train\"\n",
        "train_dataset = Dataset_from_csv(path, t, folder, tsfm)\n",
        "valid_dataset = Dataset_from_csv(path, v, folder, tsfm2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inicio de la carga de archivos.\n",
            "Progreso: 0.0%\n",
            "Progreso: 0.21%\n",
            "Progreso: 0.41%\n",
            "Progreso: 0.62%\n",
            "Progreso: 0.83%\n",
            "Progreso: 1.03%\n",
            "Progreso: 1.24%\n",
            "Progreso: 1.45%\n",
            "Progreso: 1.65%\n",
            "Progreso: 1.86%\n",
            "Progreso: 2.07%\n",
            "Progreso: 2.27%\n",
            "Progreso: 2.48%\n",
            "Progreso: 2.68%\n",
            "Progreso: 2.89%\n",
            "Progreso: 3.1%\n",
            "Progreso: 3.3%\n",
            "Progreso: 3.51%\n",
            "Progreso: 3.72%\n",
            "Progreso: 3.92%\n",
            "Progreso: 4.13%\n",
            "Progreso: 4.34%\n",
            "Progreso: 4.54%\n",
            "Progreso: 4.75%\n",
            "Progreso: 4.96%\n",
            "Progreso: 5.16%\n",
            "Progreso: 5.37%\n",
            "Progreso: 5.58%\n",
            "Progreso: 5.78%\n",
            "Progreso: 5.99%\n",
            "Progreso: 6.2%\n",
            "Progreso: 6.4%\n",
            "Progreso: 6.61%\n",
            "Progreso: 6.81%\n",
            "Progreso: 7.02%\n",
            "Progreso: 7.23%\n",
            "Progreso: 7.43%\n",
            "Progreso: 7.64%\n",
            "Progreso: 7.85%\n",
            "Progreso: 8.05%\n",
            "Progreso: 8.26%\n",
            "Progreso: 8.47%\n",
            "Progreso: 8.67%\n",
            "Progreso: 8.88%\n",
            "Progreso: 9.09%\n",
            "Progreso: 9.29%\n",
            "Progreso: 9.5%\n",
            "Progreso: 9.71%\n",
            "Progreso: 9.91%\n",
            "Progreso: 10.12%\n",
            "Progreso: 10.33%\n",
            "Progreso: 10.53%\n",
            "Progreso: 10.74%\n",
            "Progreso: 10.94%\n",
            "Progreso: 11.15%\n",
            "Progreso: 11.36%\n",
            "Progreso: 11.56%\n",
            "Progreso: 11.77%\n",
            "Progreso: 11.98%\n",
            "Progreso: 12.18%\n",
            "Progreso: 12.39%\n",
            "Progreso: 12.6%\n",
            "Progreso: 12.8%\n",
            "Progreso: 13.01%\n",
            "Progreso: 13.22%\n",
            "Progreso: 13.42%\n",
            "Progreso: 13.63%\n",
            "Progreso: 13.84%\n",
            "Progreso: 14.04%\n",
            "Progreso: 14.25%\n",
            "Progreso: 14.46%\n",
            "Progreso: 14.66%\n",
            "Progreso: 14.87%\n",
            "Progreso: 15.07%\n",
            "Progreso: 15.28%\n",
            "Progreso: 15.49%\n",
            "Progreso: 15.69%\n",
            "Progreso: 15.9%\n",
            "Progreso: 16.11%\n",
            "Progreso: 16.31%\n",
            "Progreso: 16.52%\n",
            "Progreso: 16.73%\n",
            "Progreso: 16.93%\n",
            "Progreso: 17.14%\n",
            "Progreso: 17.35%\n",
            "Progreso: 17.55%\n",
            "Progreso: 17.76%\n",
            "Progreso: 17.97%\n",
            "Progreso: 18.17%\n",
            "Progreso: 18.38%\n",
            "Progreso: 18.59%\n",
            "Progreso: 18.79%\n",
            "Progreso: 19.0%\n",
            "Progreso: 19.2%\n",
            "Progreso: 19.41%\n",
            "Progreso: 19.62%\n",
            "Progreso: 19.82%\n",
            "Progreso: 20.03%\n",
            "Progreso: 20.24%\n",
            "Progreso: 20.44%\n",
            "Progreso: 20.65%\n",
            "Progreso: 20.86%\n",
            "Progreso: 21.06%\n",
            "Progreso: 21.27%\n",
            "Progreso: 21.48%\n",
            "Progreso: 21.68%\n",
            "Progreso: 21.89%\n",
            "Progreso: 22.1%\n",
            "Progreso: 22.3%\n",
            "Progreso: 22.51%\n",
            "Progreso: 22.72%\n",
            "Progreso: 22.92%\n",
            "Progreso: 23.13%\n",
            "Progreso: 23.34%\n",
            "Progreso: 23.54%\n",
            "Progreso: 23.75%\n",
            "Progreso: 23.95%\n",
            "Progreso: 24.16%\n",
            "Progreso: 24.37%\n",
            "Progreso: 24.57%\n",
            "Progreso: 24.78%\n",
            "Progreso: 24.99%\n",
            "Progreso: 25.19%\n",
            "Progreso: 25.4%\n",
            "Progreso: 25.61%\n",
            "Progreso: 25.81%\n",
            "Progreso: 26.02%\n",
            "Progreso: 26.23%\n",
            "Progreso: 26.43%\n",
            "Progreso: 26.64%\n",
            "Progreso: 26.85%\n",
            "Progreso: 27.05%\n",
            "Progreso: 27.26%\n",
            "Progreso: 27.47%\n",
            "Progreso: 27.67%\n",
            "Progreso: 27.88%\n",
            "Progreso: 28.08%\n",
            "Progreso: 28.29%\n",
            "Progreso: 28.5%\n",
            "Progreso: 28.7%\n",
            "Progreso: 28.91%\n",
            "Progreso: 29.12%\n",
            "Progreso: 29.32%\n",
            "Progreso: 29.53%\n",
            "Progreso: 29.74%\n",
            "Progreso: 29.94%\n",
            "Progreso: 30.15%\n",
            "Progreso: 30.36%\n",
            "Progreso: 30.56%\n",
            "Progreso: 30.77%\n",
            "Progreso: 30.98%\n",
            "Progreso: 31.18%\n",
            "Progreso: 31.39%\n",
            "Progreso: 31.6%\n",
            "Progreso: 31.8%\n",
            "Progreso: 32.01%\n",
            "Progreso: 32.21%\n",
            "Progreso: 32.42%\n",
            "Progreso: 32.63%\n",
            "Progreso: 32.83%\n",
            "Progreso: 33.04%\n",
            "Progreso: 33.25%\n",
            "Progreso: 33.45%\n",
            "Progreso: 33.66%\n",
            "Progreso: 33.87%\n",
            "Progreso: 34.07%\n",
            "Progreso: 34.28%\n",
            "Progreso: 34.49%\n",
            "Progreso: 34.69%\n",
            "Progreso: 34.9%\n",
            "Progreso: 35.11%\n",
            "Progreso: 35.31%\n",
            "Progreso: 35.52%\n",
            "Progreso: 35.73%\n",
            "Progreso: 35.93%\n",
            "Progreso: 36.14%\n",
            "Progreso: 36.34%\n",
            "Progreso: 36.55%\n",
            "Progreso: 36.76%\n",
            "Progreso: 36.96%\n",
            "Progreso: 37.17%\n",
            "Progreso: 37.38%\n",
            "Progreso: 37.58%\n",
            "Progreso: 37.79%\n",
            "Progreso: 38.0%\n",
            "Progreso: 38.2%\n",
            "Progreso: 38.41%\n",
            "Progreso: 38.62%\n",
            "Progreso: 38.82%\n",
            "Progreso: 39.03%\n",
            "Progreso: 39.24%\n",
            "Progreso: 39.44%\n",
            "Progreso: 39.65%\n",
            "Progreso: 39.86%\n",
            "Progreso: 40.06%\n",
            "Progreso: 40.27%\n",
            "Progreso: 40.47%\n",
            "Progreso: 40.68%\n",
            "Progreso: 40.89%\n",
            "Progreso: 41.09%\n",
            "Progreso: 41.3%\n",
            "Progreso: 41.51%\n",
            "Progreso: 41.71%\n",
            "Progreso: 41.92%\n",
            "Progreso: 42.13%\n",
            "Progreso: 42.33%\n",
            "Progreso: 42.54%\n",
            "Progreso: 42.75%\n",
            "Progreso: 42.95%\n",
            "Progreso: 43.16%\n",
            "Progreso: 43.37%\n",
            "Progreso: 43.57%\n",
            "Progreso: 43.78%\n",
            "Progreso: 43.99%\n",
            "Progreso: 44.19%\n",
            "Progreso: 44.4%\n",
            "Progreso: 44.61%\n",
            "Progreso: 44.81%\n",
            "Progreso: 45.02%\n",
            "Progreso: 45.22%\n",
            "Progreso: 45.43%\n",
            "Progreso: 45.64%\n",
            "Progreso: 45.84%\n",
            "Progreso: 46.05%\n",
            "Progreso: 46.26%\n",
            "Progreso: 46.46%\n",
            "Progreso: 46.67%\n",
            "Progreso: 46.88%\n",
            "Progreso: 47.08%\n",
            "Progreso: 47.29%\n",
            "Progreso: 47.5%\n",
            "Progreso: 47.7%\n",
            "Progreso: 47.91%\n",
            "Progreso: 48.12%\n",
            "Progreso: 48.32%\n",
            "Progreso: 48.53%\n",
            "Progreso: 48.74%\n",
            "Progreso: 48.94%\n",
            "Progreso: 49.15%\n",
            "Progreso: 49.35%\n",
            "Progreso: 49.56%\n",
            "Progreso: 49.77%\n",
            "Progreso: 49.97%\n",
            "Progreso: 50.18%\n",
            "Progreso: 50.39%\n",
            "Progreso: 50.59%\n",
            "Progreso: 50.8%\n",
            "Progreso: 51.01%\n",
            "Progreso: 51.21%\n",
            "Progreso: 51.42%\n",
            "Progreso: 51.63%\n",
            "Progreso: 51.83%\n",
            "Progreso: 52.04%\n",
            "Progreso: 52.25%\n",
            "Progreso: 52.45%\n",
            "Progreso: 52.66%\n",
            "Progreso: 52.87%\n",
            "Progreso: 53.07%\n",
            "Progreso: 53.28%\n",
            "Progreso: 53.48%\n",
            "Progreso: 53.69%\n",
            "Progreso: 53.9%\n",
            "Progreso: 54.1%\n",
            "Progreso: 54.31%\n",
            "Progreso: 54.52%\n",
            "Progreso: 54.72%\n",
            "Progreso: 54.93%\n",
            "Progreso: 55.14%\n",
            "Progreso: 55.34%\n",
            "Progreso: 55.55%\n",
            "Progreso: 55.76%\n",
            "Progreso: 55.96%\n",
            "Progreso: 56.17%\n",
            "Progreso: 56.38%\n",
            "Progreso: 56.58%\n",
            "Progreso: 56.79%\n",
            "Progreso: 57.0%\n",
            "Progreso: 57.2%\n",
            "Progreso: 57.41%\n",
            "Progreso: 57.61%\n",
            "Progreso: 57.82%\n",
            "Progreso: 58.03%\n",
            "Progreso: 58.23%\n",
            "Progreso: 58.44%\n",
            "Progreso: 58.65%\n",
            "Progreso: 58.85%\n",
            "Progreso: 59.06%\n",
            "Progreso: 59.27%\n",
            "Progreso: 59.47%\n",
            "Progreso: 59.68%\n",
            "Progreso: 59.89%\n",
            "Progreso: 60.09%\n",
            "Progreso: 60.3%\n",
            "Progreso: 60.51%\n",
            "Progreso: 60.71%\n",
            "Progreso: 60.92%\n",
            "Progreso: 61.13%\n",
            "Progreso: 61.33%\n",
            "Progreso: 61.54%\n",
            "Progreso: 61.74%\n",
            "Progreso: 61.95%\n",
            "Progreso: 62.16%\n",
            "Progreso: 62.36%\n",
            "Progreso: 62.57%\n",
            "Progreso: 62.78%\n",
            "Progreso: 62.98%\n",
            "Progreso: 63.19%\n",
            "Progreso: 63.4%\n",
            "Progreso: 63.6%\n",
            "Progreso: 63.81%\n",
            "Progreso: 64.02%\n",
            "Progreso: 64.22%\n",
            "Progreso: 64.43%\n",
            "Progreso: 64.64%\n",
            "Progreso: 64.84%\n",
            "Progreso: 65.05%\n",
            "Progreso: 65.26%\n",
            "Progreso: 65.46%\n",
            "Progreso: 65.67%\n",
            "Progreso: 65.88%\n",
            "Progreso: 66.08%\n",
            "Progreso: 66.29%\n",
            "Progreso: 66.49%\n",
            "Progreso: 66.7%\n",
            "Progreso: 66.91%\n",
            "Progreso: 67.11%\n",
            "Progreso: 67.32%\n",
            "Progreso: 67.53%\n",
            "Progreso: 67.73%\n",
            "Progreso: 67.94%\n",
            "Progreso: 68.15%\n",
            "Progreso: 68.35%\n",
            "Progreso: 68.56%\n",
            "Progreso: 68.77%\n",
            "Progreso: 68.97%\n",
            "Progreso: 69.18%\n",
            "Progreso: 69.39%\n",
            "Progreso: 69.59%\n",
            "Progreso: 69.8%\n",
            "Progreso: 70.01%\n",
            "Progreso: 70.21%\n",
            "Progreso: 70.42%\n",
            "Progreso: 70.62%\n",
            "Progreso: 70.83%\n",
            "Progreso: 71.04%\n",
            "Progreso: 71.24%\n",
            "Progreso: 71.45%\n",
            "Progreso: 71.66%\n",
            "Progreso: 71.86%\n",
            "Progreso: 72.07%\n",
            "Progreso: 72.28%\n",
            "Progreso: 72.48%\n",
            "Progreso: 72.69%\n",
            "Progreso: 72.9%\n",
            "Progreso: 73.1%\n",
            "Progreso: 73.31%\n",
            "Progreso: 73.52%\n",
            "Progreso: 73.72%\n",
            "Progreso: 73.93%\n",
            "Progreso: 74.14%\n",
            "Progreso: 74.34%\n",
            "Progreso: 74.55%\n",
            "Progreso: 74.75%\n",
            "Progreso: 74.96%\n",
            "Progreso: 75.17%\n",
            "Progreso: 75.37%\n",
            "Progreso: 75.58%\n",
            "Progreso: 75.79%\n",
            "Progreso: 75.99%\n",
            "Progreso: 76.2%\n",
            "Progreso: 76.41%\n",
            "Progreso: 76.61%\n",
            "Progreso: 76.82%\n",
            "Progreso: 77.03%\n",
            "Progreso: 77.23%\n",
            "Progreso: 77.44%\n",
            "Progreso: 77.65%\n",
            "Progreso: 77.85%\n",
            "Progreso: 78.06%\n",
            "Progreso: 78.27%\n",
            "Progreso: 78.47%\n",
            "Progreso: 78.68%\n",
            "Progreso: 78.88%\n",
            "Progreso: 79.09%\n",
            "Progreso: 79.3%\n",
            "Progreso: 79.5%\n",
            "Progreso: 79.71%\n",
            "Progreso: 79.92%\n",
            "Progreso: 80.12%\n",
            "Progreso: 80.33%\n",
            "Progreso: 80.54%\n",
            "Progreso: 80.74%\n",
            "Progreso: 80.95%\n",
            "Progreso: 81.16%\n",
            "Progreso: 81.36%\n",
            "Progreso: 81.57%\n",
            "Progreso: 81.78%\n",
            "Progreso: 81.98%\n",
            "Progreso: 82.19%\n",
            "Progreso: 82.4%\n",
            "Progreso: 82.6%\n",
            "Progreso: 82.81%\n",
            "Progreso: 83.01%\n",
            "Progreso: 83.22%\n",
            "Progreso: 83.43%\n",
            "Progreso: 83.63%\n",
            "Progreso: 83.84%\n",
            "Progreso: 84.05%\n",
            "Progreso: 84.25%\n",
            "Progreso: 84.46%\n",
            "Progreso: 84.67%\n",
            "Progreso: 84.87%\n",
            "Progreso: 85.08%\n",
            "Progreso: 85.29%\n",
            "Progreso: 85.49%\n",
            "Progreso: 85.7%\n",
            "Progreso: 85.91%\n",
            "Progreso: 86.11%\n",
            "Progreso: 86.32%\n",
            "Progreso: 86.53%\n",
            "Progreso: 86.73%\n",
            "Progreso: 86.94%\n",
            "Progreso: 87.15%\n",
            "Progreso: 87.35%\n",
            "Progreso: 87.56%\n",
            "Progreso: 87.76%\n",
            "Progreso: 87.97%\n",
            "Progreso: 88.18%\n",
            "Progreso: 88.38%\n",
            "Progreso: 88.59%\n",
            "Progreso: 88.8%\n",
            "Progreso: 89.0%\n",
            "Progreso: 89.21%\n",
            "Progreso: 89.42%\n",
            "Progreso: 89.62%\n",
            "Progreso: 89.83%\n",
            "Progreso: 90.04%\n",
            "Progreso: 90.24%\n",
            "Progreso: 90.45%\n",
            "Progreso: 90.66%\n",
            "Progreso: 90.86%\n",
            "Progreso: 91.07%\n",
            "Progreso: 91.28%\n",
            "Progreso: 91.48%\n",
            "Progreso: 91.69%\n",
            "Progreso: 91.89%\n",
            "Progreso: 92.1%\n",
            "Progreso: 92.31%\n",
            "Progreso: 92.51%\n",
            "Progreso: 92.72%\n",
            "Progreso: 92.93%\n",
            "Progreso: 93.13%\n",
            "Progreso: 93.34%\n",
            "Progreso: 93.55%\n",
            "Progreso: 93.75%\n",
            "Progreso: 93.96%\n",
            "Progreso: 94.17%\n",
            "Progreso: 94.37%\n",
            "Progreso: 94.58%\n",
            "Progreso: 94.79%\n",
            "Progreso: 94.99%\n",
            "Progreso: 95.2%\n",
            "Progreso: 95.41%\n",
            "Progreso: 95.61%\n",
            "Progreso: 95.82%\n",
            "Progreso: 96.02%\n",
            "Progreso: 96.23%\n",
            "Progreso: 96.44%\n",
            "Progreso: 96.64%\n",
            "Progreso: 96.85%\n",
            "Progreso: 97.06%\n",
            "Progreso: 97.26%\n",
            "Progreso: 97.47%\n",
            "Progreso: 97.68%\n",
            "Progreso: 97.88%\n",
            "Progreso: 98.09%\n",
            "Progreso: 98.3%\n",
            "Progreso: 98.5%\n",
            "Progreso: 98.71%\n",
            "Progreso: 98.92%\n",
            "Progreso: 99.12%\n",
            "Progreso: 99.33%\n",
            "Progreso: 99.54%\n",
            "Progreso: 99.74%\n",
            "Progreso: 99.95%\n",
            "Inicio de la carga de archivos.\n",
            "Progreso: 0.0%\n",
            "Progreso: 0.83%\n",
            "Progreso: 1.65%\n",
            "Progreso: 2.48%\n",
            "Progreso: 3.3%\n",
            "Progreso: 4.13%\n",
            "Progreso: 4.96%\n",
            "Progreso: 5.78%\n",
            "Progreso: 6.61%\n",
            "Progreso: 7.43%\n",
            "Progreso: 8.26%\n",
            "Progreso: 9.09%\n",
            "Progreso: 9.91%\n",
            "Progreso: 10.74%\n",
            "Progreso: 11.57%\n",
            "Progreso: 12.39%\n",
            "Progreso: 13.22%\n",
            "Progreso: 14.04%\n",
            "Progreso: 14.87%\n",
            "Progreso: 15.7%\n",
            "Progreso: 16.52%\n",
            "Progreso: 17.35%\n",
            "Progreso: 18.17%\n",
            "Progreso: 19.0%\n",
            "Progreso: 19.83%\n",
            "Progreso: 20.65%\n",
            "Progreso: 21.48%\n",
            "Progreso: 22.3%\n",
            "Progreso: 23.13%\n",
            "Progreso: 23.96%\n",
            "Progreso: 24.78%\n",
            "Progreso: 25.61%\n",
            "Progreso: 26.44%\n",
            "Progreso: 27.26%\n",
            "Progreso: 28.09%\n",
            "Progreso: 28.91%\n",
            "Progreso: 29.74%\n",
            "Progreso: 30.57%\n",
            "Progreso: 31.39%\n",
            "Progreso: 32.22%\n",
            "Progreso: 33.04%\n",
            "Progreso: 33.87%\n",
            "Progreso: 34.7%\n",
            "Progreso: 35.52%\n",
            "Progreso: 36.35%\n",
            "Progreso: 37.17%\n",
            "Progreso: 38.0%\n",
            "Progreso: 38.83%\n",
            "Progreso: 39.65%\n",
            "Progreso: 40.48%\n",
            "Progreso: 41.31%\n",
            "Progreso: 42.13%\n",
            "Progreso: 42.96%\n",
            "Progreso: 43.78%\n",
            "Progreso: 44.61%\n",
            "Progreso: 45.44%\n",
            "Progreso: 46.26%\n",
            "Progreso: 47.09%\n",
            "Progreso: 47.91%\n",
            "Progreso: 48.74%\n",
            "Progreso: 49.57%\n",
            "Progreso: 50.39%\n",
            "Progreso: 51.22%\n",
            "Progreso: 52.04%\n",
            "Progreso: 52.87%\n",
            "Progreso: 53.7%\n",
            "Progreso: 54.52%\n",
            "Progreso: 55.35%\n",
            "Progreso: 56.18%\n",
            "Progreso: 57.0%\n",
            "Progreso: 57.83%\n",
            "Progreso: 58.65%\n",
            "Progreso: 59.48%\n",
            "Progreso: 60.31%\n",
            "Progreso: 61.13%\n",
            "Progreso: 61.96%\n",
            "Progreso: 62.78%\n",
            "Progreso: 63.61%\n",
            "Progreso: 64.44%\n",
            "Progreso: 65.26%\n",
            "Progreso: 66.09%\n",
            "Progreso: 66.91%\n",
            "Progreso: 67.74%\n",
            "Progreso: 68.57%\n",
            "Progreso: 69.39%\n",
            "Progreso: 70.22%\n",
            "Progreso: 71.05%\n",
            "Progreso: 71.87%\n",
            "Progreso: 72.7%\n",
            "Progreso: 73.52%\n",
            "Progreso: 74.35%\n",
            "Progreso: 75.18%\n",
            "Progreso: 76.0%\n",
            "Progreso: 76.83%\n",
            "Progreso: 77.65%\n",
            "Progreso: 78.48%\n",
            "Progreso: 79.31%\n",
            "Progreso: 80.13%\n",
            "Progreso: 80.96%\n",
            "Progreso: 81.78%\n",
            "Progreso: 82.61%\n",
            "Progreso: 83.44%\n",
            "Progreso: 84.26%\n",
            "Progreso: 85.09%\n",
            "Progreso: 85.91%\n",
            "Progreso: 86.74%\n",
            "Progreso: 87.57%\n",
            "Progreso: 88.39%\n",
            "Progreso: 89.22%\n",
            "Progreso: 90.05%\n",
            "Progreso: 90.87%\n",
            "Progreso: 91.7%\n",
            "Progreso: 92.52%\n",
            "Progreso: 93.35%\n",
            "Progreso: 94.18%\n",
            "Progreso: 95.0%\n",
            "Progreso: 95.83%\n",
            "Progreso: 96.65%\n",
            "Progreso: 97.48%\n",
            "Progreso: 98.31%\n",
            "Progreso: 99.13%\n",
            "Progreso: 99.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RCEaDbaPQbC"
      },
      "source": [
        "## Modelos "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxg9sDkpaykh"
      },
      "source": [
        "Para entrenarlos se seguirá el siguiente proceso:\n",
        "\n",
        "\n",
        "1.   Carga de los datos en un formato de 128x128\n",
        "2.   Entrenamiento a aproximadamente una razón de aprendizaje de 0'0003.\n",
        "3.   Una vez el aprendizaje se ha ralentizado cambiar los datos al formato de 256x256.\n",
        "4.   Continuar entrenando unas pocas iteracciones a 0'0003 y bajar su valor en cuanto se ralentice a 0'00003.\n",
        "\n",
        "Se ha probado el uso de la política de entrenamiento *One Cycle* y no parece dar un resultado mejor que el de un entrenamiento normal. En el caso de que se quiera usar el *Scheduler* están las líneas necesarias comentandas dentro de la clase *Learner*.\n",
        "\n",
        "El umbral que aparece como parámetro de la función *fit* de la clase *Learner* indica a partir de qué nivel de activación en la neurona de salida se considerará que es un melanoma. En este caso parece que el mejor número para este problema es 0.5, pero podría variar si empleamos esta arquitectura para resolver otro problema (como una clasificación multietiqueta o una clasificación con una clase \"desconocido\", como es este caso).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62df0BX2LJsr"
      },
      "source": [
        "### Resnet modificada\n",
        "\n",
        "Resblock modificado según el paper *Bag of Tricks for Image Classification with Convolutional Neural Networks* (disponible en arxiv.org/pdf/1812.01187.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVvkLKKLVd6p"
      },
      "source": [
        "def noop(x): return x # Función identidad\n",
        "\n",
        "def conv(ni, nf, ks=3, stride=1, bias=False): #nn.Conv2d simplificada con padding de tamaño dependiente del tamaño de filtro\n",
        "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
        "\n",
        "act_fn = nn.ReLU(inplace=True)\n",
        "\n",
        "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, activacion=True):\n",
        "    \"\"\"\n",
        "    Bloque Conv+BN+ReLU(opcional)\n",
        "    BN con gamma inicializada a cero de forma opcional\n",
        "    \"\"\"\n",
        "    bn = nn.BatchNorm2d(nf)\n",
        "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.) # Truco para anular la mitad que procesa del ResBlock y facilitar el entrenamiento inicial.\n",
        "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
        "    if activacion: layers.append(act_fn) # Optativo porque en la última convolución del ResBlock la activación va tras la suma de los dos caminos.\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbOBEYGhUbjT"
      },
      "source": [
        "class Resblock(nn.Module):\n",
        "    def __init__(self, ni, nh, stride=1):\n",
        "        super().__init__()\n",
        "        # Camino A\n",
        "        layers = [conv_layer(ni, nh, 3, stride=stride), conv_layer(nh, nh, 3, zero_bn=True, activacion=False)]\n",
        "        self.convs = nn.Sequential(*layers)\n",
        "        # Camino B\n",
        "        self.idconv = noop if ni==nh else conv_layer(ni, nh, 1, activacion=False) # Si difiere el número de canales\n",
        "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True)        # Si difiere el tamaño de los datos\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsvjnFojVU9A"
      },
      "source": [
        "def group(ni, nf, n_blocks, stride):\n",
        "    \"\"\"\n",
        "    Crea un conjunto de ResBlocks y los devuelve.\n",
        "    Solo se usará stride=2 en el primer bloque del grupo\n",
        "    Tendrán el mismo número de filtros de salida que de entrada excepto en\n",
        "    el primer bloque del grupo.\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        *[Resblock(ni if i==0 else nf, nf, stride if i==0 else 1) for i in range(n_blocks)]\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obs8by98bkEy"
      },
      "source": [
        "def init_weights(m):\n",
        "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
        "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
        "    for l in m.children(): init_weights(l) # Recursivo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSQUfOD8SFx4"
      },
      "source": [
        "class XResNet18(nn.Sequential):\n",
        "    @classmethod\n",
        "    def create(cls, c_in=3, c_out=1):\n",
        "        list_nf = [c_in, (c_in+1)*8, 64, 64]\n",
        "        inicio = [conv_layer(list_nf[i], list_nf[i+1], 3, stride=2 if i==0 else 1) for i in range(3)]\n",
        "        list_nf = [64, 64, 128, 256, 512]\n",
        "        layers = [2, 2, 2, 2]\n",
        "        b_groups = [group(list_nf[i], list_nf[i+1], n_blocks=1, stride=1 if i==0 else 2) for i,l in enumerate(layers)]\n",
        "        \n",
        "        resnet = cls(*inicio,\n",
        "                     nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "                     *b_groups,\n",
        "                     nn.AdaptiveAvgPool2d(1), # Media entre canales\n",
        "                     nn.Flatten(),\n",
        "                     nn.Linear(list_nf[-1], c_out)\n",
        "                     )\n",
        "        \n",
        "        init_weights(resnet)\n",
        "        return resnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnsdnquTbqJ6"
      },
      "source": [
        "model = XResNet18.create()\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shbXKTeRb11o",
        "outputId": "8a2d1ef6-7f81-4fdd-91d5-46c0b60b1a7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XResNet18(\n",
              "  (0): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (1): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (2): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): Resblock(\n",
              "      (convs): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): Resblock(\n",
              "      (convs): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Sequential(\n",
              "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (idconv): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): Resblock(\n",
              "      (convs): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (idconv): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): Resblock(\n",
              "      (convs): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Sequential(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (idconv): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "  )\n",
              "  (8): AdaptiveAvgPool2d(output_size=1)\n",
              "  (9): Flatten(start_dim=1, end_dim=-1)\n",
              "  (10): Linear(in_features=512, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTJFczoncsmy"
      },
      "source": [
        "def accuracy(y_pred, y):\n",
        "    n_true = torch.sum(y_pred.data.max(1, keepdim=True)[1].squeeze(-1) == y).item()\n",
        "    n_samples = y.size()[0]\n",
        "    return n_true, n_samples\n",
        "\n",
        "def multilabel_accuracy(y_pred, y, threshold):\n",
        "    n_true, n_samples = 0, len(y_pred)\n",
        "    for pred,target in zip(y_pred, y):\n",
        "        if len(pred[pred>threshold])>1:\n",
        "            pred_label = (pred==(pred[pred>threshold].max())).nonzero()\n",
        "        else:\n",
        "            pred_label = ((pred>threshold)==True).nonzero()\n",
        "        label = (target==True).nonzero()\n",
        "        if str(pred_label)==str(label): n_true += 1\n",
        "    return n_true, n_samples\n",
        "\n",
        "class Learner():\n",
        "    def __init__(self, model, train, valid, optim, loss_fn):\n",
        "        self.model = model\n",
        "        self.train = train\n",
        "        self.valid = valid\n",
        "        self.optim = optim\n",
        "        self.loss_fn = loss_fn\n",
        "        self.lr = 0\n",
        "        self.losses_train = []\n",
        "        self.losses_valid = []\n",
        "\n",
        "    def fit(self, epochs, lr, max_lr, threshold):\n",
        "        #scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optim, max_lr=max_lr, steps_per_epoch=len(self.train), epochs=epochs)\n",
        "        if lr != self.lr:\n",
        "            self.lr == lr\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            acc_loss = 0\n",
        "            n_true = 0\n",
        "            n_samples = 0\n",
        "            acc = 0\n",
        "            \n",
        "            acc_loss_val = 0\n",
        "            n_true_val = 0\n",
        "            n_samples_val = 0\n",
        "\n",
        "            # Training\n",
        "            self.model = self.model.train()\n",
        "            for count, sample in enumerate(self.train):\n",
        "                X_batch = sample[\"image\"].to(\"cuda:0\")\n",
        "                y_batch = sample[\"label\"].float().to(\"cuda:0\")\n",
        "                y_pred = self.model(X_batch)\n",
        "                loss = self.loss_fn(y_pred.squeeze(-1), y_batch)\n",
        "                n_true_b, n_samples_b = multilabel_accuracy(y_pred.squeeze(-1), y_batch, threshold) \n",
        "                n_true += n_true_b\n",
        "                n_samples += n_samples_b\n",
        "                if count % 50 == 0:\n",
        "                    acc = n_true/n_samples\n",
        "                    print(f\"Train epoch {epoch+1}: [{count}/{len(self.train)}\\tLoss: {round(loss.item(), 3)}\\tAcc: {round(acc*100, 2)}%]\")\n",
        "                acc_loss += loss.item()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                #scheduler.step()\n",
        "\n",
        "            # Validation\n",
        "            self.model = self.model.eval()\n",
        "            i=0\n",
        "            with torch.no_grad():\n",
        "                for sample_val in self.valid:\n",
        "                    X_batch = sample_val[\"image\"].to(\"cuda:0\")\n",
        "                    y_batch = sample_val[\"label\"].float().to(\"cuda:0\")\n",
        "                    y_pred = self.model(X_batch)\n",
        "                    loss = self.loss_fn(y_pred.squeeze(-1), y_batch)\n",
        "                    n_true_b, n_samples_b = multilabel_accuracy(y_pred.squeeze(-1), y_batch, threshold) \n",
        "                    n_true_val += n_true_b\n",
        "                    n_samples_val += n_samples_b\n",
        "                    acc_loss_val += loss.item()\n",
        "\n",
        "            acc = n_true/n_samples\n",
        "            acc_val = n_true_val/n_samples_val\n",
        "            \n",
        "            print(f\"Train epoch {epoch+1}: Train -> [Loss: {round(acc_loss/len(self.train), 3)}\\tAcc: {round(acc*100, 2)}%], Valid -> [Loss: {round(acc_loss_val/len(self.valid), 3)}\\tAcc: {round(acc_val*100, 2)}%]\\n\")\n",
        "            self.losses_train.append(acc_loss/len(self.train))\n",
        "            self.losses_valid.append(acc_loss_val/len(self.valid))\n",
        "\n",
        "    def plot():\n",
        "        plt.plot(learner.losses_train)\n",
        "        plt.plot(learner.losses_valid)\n",
        "        plt.ylabel('Error')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.legend([\"Entrenamiento\", \"Validación\"])\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jZNSJ0fcsJC"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yWvOwyIgH9U"
      },
      "source": [
        "Se ajusta de forma automáticamente el tamaño del lote en función del tamaño de las imágenes para que la RAM de la GPU no colapse, pues eso nos obligaría a comenzar de nuevo con la ejecución tras reiniciar el entorno de ejecución."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOMYfOlNcsBE"
      },
      "source": [
        "if size == 128: \n",
        "    bs=256\n",
        "else: \n",
        "    bs = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=0)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=bs, shuffle=True, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAX1h8fbdiHn"
      },
      "source": [
        "learner = Learner(model, train_dataloader, valid_dataloader, optimizer, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0FpsKazQqPq"
      },
      "source": [
        "En ocasiones, al ejecutar la celda de abajo aparece un error relacionado con \"ndim\". Sin conocer el motivo detrás de él, se soluciona volviendo a cargar los datos en RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwh1AsnwdmNB"
      },
      "source": [
        "learner.train=train_dataloader\n",
        "learner.valid=valid_dataloader\n",
        "learner.fit(3, 0.0003, 0.1, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-Aj4QzjdtPW"
      },
      "source": [
        "learner.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCjGZEctNwYJ"
      },
      "source": [
        "### EfficientNet con Transfer Learning\n",
        "\n",
        "Esta arquitectura se descarga con unos pesos ya entrenados con Imagenet, lo que facilita el aprendizaje."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTjIAniEHK7X",
        "outputId": "024c6cb2-81d2-4df0-f65d-5484e1bf36d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378,
          "referenced_widgets": [
            "848d4aceef64437ebfcea3df53b7547d",
            "d84ccc23a49e4458be366089e12e4c64",
            "54293a2df7c74dfe95e55b0064470277",
            "20279f387846425faa55c9ab157b871d",
            "c91d255980d945c19dbbd9bccc6f1ccb",
            "3d9a1cc7c41d4c4a806bbbc410ed3747",
            "41b2187312a04e66bda791453715fd01",
            "a2fff500aff3435db56bedf4fc7424b7"
          ]
        }
      },
      "source": [
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "def NewEfficientNet(c_out=1):\n",
        "    model = EfficientNet.from_pretrained('efficientnet-b1')\n",
        "    model._fc = nn.Linear(in_features=1280, out_features=c_out, bias=True)\n",
        "    return model\n",
        "\n",
        "model = NewEfficientNet()\n",
        "model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/83/f9c5f44060f996279e474185ebcbd8dbd91179593bffb9abe3afa55d085b/efficientnet_pytorch-0.7.0.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-cp36-none-any.whl size=16031 sha256=651fbb4f40c660972d1d689b599746ff002c58d77f4008534df6efdef188e33c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b1-f1951068.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "848d4aceef64437ebfcea3df53b7547d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=31519111.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkOgVsTZag2d",
        "outputId": "04788f7a-4863-4db6-82aa-ba065cd7e09d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (_conv_stem): Conv2dStaticSamePadding(\n",
              "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "    (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "  )\n",
              "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_blocks): ModuleList(\n",
              "    (0): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (1): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        16, 16, kernel_size=(3, 3), stride=(1, 1), groups=16, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        16, 4, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        4, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (2): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (3): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (4): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (5): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (6): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (7): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (8): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (9): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (10): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (11): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (12): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (13): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (14): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (15): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (16): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (17): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (18): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (19): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (20): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (21): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (22): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1920, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1920, 1920, kernel_size=(3, 3), stride=(1, 1), groups=1920, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1920, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1920, 80, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        80, 1920, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "  )\n",
              "  (_conv_head): Conv2dStaticSamePadding(\n",
              "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "    (static_padding): Identity()\n",
              "  )\n",
              "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "  (_dropout): Dropout(p=0.2, inplace=False)\n",
              "  (_fc): Linear(in_features=1280, out_features=1, bias=True)\n",
              "  (_swish): MemoryEfficientSwish()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co9BSksubBen"
      },
      "source": [
        "def accuracy(y_pred, y):\n",
        "    n_true = torch.sum(y_pred.data.max(1, keepdim=True)[1].squeeze(-1) == y).item()\n",
        "    n_samples = y.size()[0]\n",
        "    return n_true, n_samples\n",
        "\n",
        "def multilabel_accuracy(y_pred, y, threshold):\n",
        "    n_true, n_samples = 0, len(y_pred)\n",
        "    for pred,target in zip(y_pred, y):\n",
        "        if len(pred[pred>threshold])>1:\n",
        "            pred_label = (pred==(pred[pred>threshold].max())).nonzero()\n",
        "        else:\n",
        "            pred_label = ((pred>threshold)==True).nonzero()\n",
        "        label = (target==True).nonzero()\n",
        "        if str(pred_label)==str(label): n_true += 1\n",
        "    return n_true, n_samples\n",
        "\n",
        "class Learner():\n",
        "    def __init__(self, model, train, valid, optim, loss_fn):\n",
        "        self.model = model\n",
        "        self.train = train\n",
        "        self.valid = valid\n",
        "        self.optim = optim\n",
        "        self.loss_fn = loss_fn\n",
        "        self.lr = 0\n",
        "        self.losses_train = []\n",
        "        self.losses_valid = []\n",
        "\n",
        "    def fit(self, epochs, lr, max_lr, threshold):\n",
        "        #scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optim, max_lr=max_lr, steps_per_epoch=len(self.train), epochs=epochs)\n",
        "        if lr != self.lr:\n",
        "            self.lr == lr\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            acc_loss = 0\n",
        "            n_true = 0\n",
        "            n_samples = 0\n",
        "            acc = 0\n",
        "            \n",
        "            acc_loss_val = 0\n",
        "            n_true_val = 0\n",
        "            n_samples_val = 0\n",
        "\n",
        "            # Training\n",
        "            self.model = self.model.train()\n",
        "            for count, sample in enumerate(self.train):\n",
        "                X_batch = sample[\"image\"].to(\"cuda:0\")\n",
        "                y_batch = sample[\"label\"].float().to(\"cuda:0\")\n",
        "                y_pred = self.model(X_batch)\n",
        "                loss = self.loss_fn(y_pred.squeeze(-1), y_batch)\n",
        "                n_true_b, n_samples_b = multilabel_accuracy(y_pred.squeeze(-1), y_batch, threshold) \n",
        "                n_true += n_true_b\n",
        "                n_samples += n_samples_b\n",
        "                if count % 50 == 0:\n",
        "                    acc = n_true/n_samples\n",
        "                    print(f\"Train epoch {epoch+1}: [{count}/{len(self.train)}\\tLoss: {round(loss.item(), 3)}\\tAcc: {round(acc*100, 2)}%]\")\n",
        "                acc_loss += loss.item()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                #scheduler.step()\n",
        "\n",
        "            # Validation\n",
        "            self.model = self.model.eval()\n",
        "            i=0\n",
        "            with torch.no_grad():\n",
        "                for sample_val in self.valid:\n",
        "                    X_batch = sample_val[\"image\"].to(\"cuda:0\")\n",
        "                    y_batch = sample_val[\"label\"].float().to(\"cuda:0\")\n",
        "                    y_pred = self.model(X_batch)\n",
        "                    loss = self.loss_fn(y_pred.squeeze(-1), y_batch)\n",
        "                    n_true_b, n_samples_b = multilabel_accuracy(y_pred.squeeze(-1), y_batch, threshold) \n",
        "                    n_true_val += n_true_b\n",
        "                    n_samples_val += n_samples_b\n",
        "                    acc_loss_val += loss.item()\n",
        "\n",
        "            acc = n_true/n_samples\n",
        "            acc_val = n_true_val/n_samples_val\n",
        "            \n",
        "            print(f\"Train epoch {epoch+1}: Train -> [Loss: {round(acc_loss/len(self.train), 3)}\\tAcc: {round(acc*100, 2)}%], Valid -> [Loss: {round(acc_loss_val/len(self.valid), 3)}\\tAcc: {round(acc_val*100, 2)}%]\\n\")\n",
        "            self.losses_train.append(acc_loss/len(self.train))\n",
        "            self.losses_valid.append(acc_loss_val/len(self.valid))\n",
        "\n",
        "    def plot(self):\n",
        "        plt.plot(learner.losses_train)\n",
        "        plt.plot(learner.losses_valid)\n",
        "        plt.ylabel('Error')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.legend([\"Entrenamiento\", \"Validación\"])\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5AekjfabFKO"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUVvuhuVbJTy"
      },
      "source": [
        "if size == 128: \n",
        "    bs=256\n",
        "else: \n",
        "    bs = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=0)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=bs, shuffle=True, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwrsXl0ibNKo"
      },
      "source": [
        "learner = Learner(model, train_dataloader, valid_dataloader, optimizer, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDi0q2u7oIeZ"
      },
      "source": [
        "En ocasiones, al ejecutar la celda de abajo aparece un error relacionado con \"ndim\". Sin conocer el motivo detrás de él, se soluciona volviendo a cargar los datos en RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9W9fJuobNtV",
        "outputId": "faf63da6-52e9-4291-ed7d-c22565f2ed0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "learner.train=train_dataloader\n",
        "learner.valid=valid_dataloader\n",
        "learner.fit(3, 0.0003, 0.1, 0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train epoch 1: [0/38\tLoss: 0.145\tAcc: 94.92%]\n",
            "Train epoch 1: Train -> [Loss: 0.15\tAcc: 93.94%], Valid -> [Loss: 0.237\tAcc: 89.96%]\n",
            "\n",
            "Train epoch 2: [0/38\tLoss: 0.102\tAcc: 96.09%]\n",
            "Train epoch 2: Train -> [Loss: 0.125\tAcc: 94.87%], Valid -> [Loss: 0.205\tAcc: 92.15%]\n",
            "\n",
            "Train epoch 3: [0/38\tLoss: 0.089\tAcc: 97.66%]\n",
            "Train epoch 3: Train -> [Loss: 0.112\tAcc: 95.56%], Valid -> [Loss: 0.25\tAcc: 92.9%]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJXTPcXPbT7_"
      },
      "source": [
        "learner.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NmTddRqOJNW"
      },
      "source": [
        "### EfficientNet con Transfer Learning y metadatos \n",
        "Similar al apartado anterior, aquí se combina la red preentrenada con los metadatos de la imagen analizada. Para ello se pasan estos metadatos por un percetrón multicapa y la salida se combina con la salida de las capas convolucionales de EfficientNet. Con este nuevo input se volverá a pasar por un perceptrón multicapa que tendrá como output el resultado de la red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgvkFalLONbm",
        "outputId": "e51ac575-ad9e-4c69-aec1-34d0f4fb3ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "class MetaEfficientNet(nn.Module):\n",
        "    def __init__(self, n_neurons=128):\n",
        "        super().__init__()\n",
        "        self.conv = EfficientNet.from_pretrained('efficientnet-b1')\n",
        "        self.conv._fc = nn.Linear(in_features=1280, out_features=512, bias=True)\n",
        "        self.MP = nn.Sequential(nn.Linear(12, n_neurons),\n",
        "                                nn.BatchNorm1d(n_neurons),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(p=0.2)\n",
        "                                )\n",
        "        self.out = nn.Linear(512+n_neurons, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        image, meta = x\n",
        "        output_image = self.conv(image)\n",
        "        output_meta = self.MP(meta)\n",
        "        output = self.out(torch.cat((output_image, output_meta), dim=1))\n",
        "        return output\n",
        "\n",
        "net = MetaEfficientNet(256)\n",
        "model = net.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Loaded pretrained weights for efficientnet-b1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0bdSjaaenv3",
        "outputId": "0831a7f9-472a-41aa-9f36-17387b3e8f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MetaEfficientNet(\n",
              "  (conv): EfficientNet(\n",
              "    (_conv_stem): Conv2dStaticSamePadding(\n",
              "      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "    )\n",
              "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (_blocks): ModuleList(\n",
              "      (0): MBConvBlock(\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (1): MBConvBlock(\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          16, 16, kernel_size=(3, 3), stride=(1, 1), groups=16, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          16, 4, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          4, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (2): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (3): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (4): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (5): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (6): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (7): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (8): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (9): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (10): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (11): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (12): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (13): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (14): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (15): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (16): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (17): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (18): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (19): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (20): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (21): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (22): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1920, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1920, 1920, kernel_size=(3, 3), stride=(1, 1), groups=1920, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1920, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1920, 80, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          80, 1920, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "    )\n",
              "    (_conv_head): Conv2dStaticSamePadding(\n",
              "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "      (static_padding): Identity()\n",
              "    )\n",
              "    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "    (_dropout): Dropout(p=0.2, inplace=False)\n",
              "    (_fc): Linear(in_features=1280, out_features=512, bias=True)\n",
              "    (_swish): MemoryEfficientSwish()\n",
              "  )\n",
              "  (MP): Sequential(\n",
              "    (0): Linear(in_features=12, out_features=256, bias=True)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (out): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGIyybbgesxQ"
      },
      "source": [
        "def accuracy(y_pred, y):\n",
        "    n_true = torch.sum(y_pred.data.max(1, keepdim=True)[1].squeeze(-1) == y).item()\n",
        "    n_samples = y.size()[0]\n",
        "    return n_true, n_samples\n",
        "\n",
        "def multilabel_accuracy(y_pred, y, threshold):\n",
        "    n_true, n_samples = 0, len(y_pred)\n",
        "    for pred,target in zip(y_pred, y):\n",
        "        if len(pred[pred>threshold])>1:\n",
        "            pred_label = (pred==(pred[pred>threshold].max())).nonzero()\n",
        "        else:\n",
        "            pred_label = ((pred>threshold)==True).nonzero()\n",
        "        label = (target==True).nonzero()\n",
        "        if str(pred_label)==str(label): n_true += 1\n",
        "    return n_true, n_samples\n",
        "\n",
        "class Learner():\n",
        "    def __init__(self, model, train, valid, optim, loss_fn):\n",
        "        self.model = model\n",
        "        self.train = train\n",
        "        self.valid = valid\n",
        "        self.optim = optim\n",
        "        self.loss_fn = loss_fn\n",
        "        self.lr = 0\n",
        "        self.losses_train = []\n",
        "        self.losses_valid = []\n",
        "\n",
        "    def fit(self, epochs, lr, max_lr, threshold):\n",
        "        #scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optim, max_lr=max_lr, steps_per_epoch=len(self.train), epochs=epochs)\n",
        "        if lr != self.lr:\n",
        "            self.lr == lr\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            acc_loss = 0\n",
        "            n_true = 0\n",
        "            n_samples = 0\n",
        "            acc = 0\n",
        "            \n",
        "            acc_loss_val = 0\n",
        "            n_true_val = 0\n",
        "            n_samples_val = 0\n",
        "\n",
        "            # Training\n",
        "            self.model = self.model.train()\n",
        "            for count, sample in enumerate(self.train):\n",
        "                data, meta = sample\n",
        "                X_batch = data[\"image\"].to(\"cuda:0\")\n",
        "                y_batch = data[\"label\"].float().to(\"cuda:0\")\n",
        "                y_pred = self.model([X_batch, meta.to(\"cuda:0\")])\n",
        "                loss = self.loss_fn(y_pred.squeeze(-1), y_batch)\n",
        "                n_true_b, n_samples_b = multilabel_accuracy(y_pred.squeeze(-1), y_batch, threshold) \n",
        "                n_true += n_true_b\n",
        "                n_samples += n_samples_b\n",
        "                if count % 50 == 0:\n",
        "                    acc = n_true/n_samples\n",
        "                    print(f\"Train epoch {epoch+1}: [{count}/{len(self.train)}\\tLoss: {round(loss.item(), 3)}\\tAcc: {round(acc*100, 2)}%]\")\n",
        "                acc_loss += loss.item()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                #scheduler.step()\n",
        "\n",
        "            # Validation\n",
        "            self.model = self.model.eval()\n",
        "            i=0\n",
        "            with torch.no_grad():\n",
        "                for sample_val in self.valid:\n",
        "                    data, meta = sample_val\n",
        "                    X_batch = data[\"image\"].to(\"cuda:0\")\n",
        "                    y_batch = data[\"label\"].float().to(\"cuda:0\")\n",
        "                    y_pred = self.model([X_batch, meta.to(\"cuda:0\")])\n",
        "                    loss = self.loss_fn(y_pred.squeeze(-1), y_batch)\n",
        "                    n_true_b, n_samples_b = multilabel_accuracy(y_pred.squeeze(-1), y_batch, threshold) \n",
        "                    n_true_val += n_true_b\n",
        "                    n_samples_val += n_samples_b\n",
        "                    acc_loss_val += loss.item()\n",
        "\n",
        "            acc = n_true/n_samples\n",
        "            acc_val = n_true_val/n_samples_val\n",
        "            \n",
        "            print(f\"Train epoch {epoch+1}: Train -> [Loss: {round(acc_loss/len(self.train), 3)}\\tAcc: {round(acc*100, 2)}%], Valid -> [Loss: {round(acc_loss_val/len(self.valid), 3)}\\tAcc: {round(acc_val*100, 2)}%]\\n\")\n",
        "            self.losses_train.append(acc_loss/len(self.train))\n",
        "            self.losses_valid.append(acc_loss_val/len(self.valid))\n",
        "\n",
        "    def plot():\n",
        "        plt.plot(learner.losses_train)\n",
        "        plt.plot(learner.losses_valid)\n",
        "        plt.ylabel('Error')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.legend([\"Entrenamiento\", \"Validación\"])\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqtbPb0ifGHY"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6HY-hVsfF4_"
      },
      "source": [
        "if size == 128: \n",
        "    bs=256\n",
        "else: \n",
        "    bs = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=0)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=bs, shuffle=True, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozzQ2bD7fObd"
      },
      "source": [
        "learner = Learner(model, train_dataloader, valid_dataloader, optimizer, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYlzI2ipQkS8"
      },
      "source": [
        "En ocasiones, al ejecutar la celda de abajo aparece un error relacionado con \"ndim\". Sin conocer el motivo detrás de él, se soluciona volviendo a cargar los datos en RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwhN3jh5fO0C"
      },
      "source": [
        "learner.train=train_dataloader\n",
        "learner.valid=valid_dataloader\n",
        "learner.fit(3, 0.0003, 0.1, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcpcNpFPfPPv"
      },
      "source": [
        "learner.plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}